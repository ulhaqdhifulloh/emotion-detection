{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Emotion Detection Training\n",
    "This notebook trains a CNN model for emotion detection with comprehensive evaluation metrics and visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "import json\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for better plots\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "class Config:\n",
    "    # Paths\n",
    "    data_dir = '../data'\n",
    "    train_dir = os.path.join(data_dir, 'train')\n",
    "    val_dir = os.path.join(data_dir, 'val')\n",
    "    models_dir = '../models'
    results_dir = '../results'\n",
    "    \n",
    "    # Training parameters\n",
    "    batch_size = 32\n",
    "    learning_rate = 0.001\n",
    "    num_epochs = 50\n",
    "    patience = 10  # Early stopping\n",
    "    \n",
    "    # Model parameters\n",
    "    img_size = 224\n",
    "    num_classes = 7\n",
    "    \n",
    "    # Device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # Model save name\n",
    "    model_name = 'cnn_emotion_model.pth'\n",
    "\n",
    "config = Config()\n",
    "print(f\"Using device: {config.device}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data transforms with augmentation\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((config.img_size, config.img_size)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((config.img_size, config.img_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = datasets.ImageFolder(config.train_dir, transform=train_transform)\n",
    "val_dataset = datasets.ImageFolder(config.val_dir, transform=val_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=config.batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "# Get class names\n",
    "class_names = train_dataset.classes\n",
    "print(f\"Classes: {class_names}\")\n",
    "print(f\"Number of training samples: {len(train_dataset)}\")\n",
    "print(f\"Number of validation samples: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize dataset distribution\n",
    "def plot_dataset_distribution():\n",
    "    train_counts = [len([f for f in os.listdir(os.path.join(config.train_dir, cls)) \n",
    "                        if f.lower().endswith(('.png', '.jpg', '.jpeg'))]) for cls in class_names]\n",
    "    val_counts = [len([f for f in os.listdir(os.path.join(config.val_dir, cls)) \n",
    "                      if f.lower().endswith(('.png', '.jpg', '.jpeg'))]) for cls in class_names]\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Training distribution\n",
    "    ax1.bar(class_names, train_counts, color='skyblue', alpha=0.8)\n",
    "    ax1.set_title('Training Dataset Distribution', fontsize=14, fontweight='bold')\n",
    "    ax1.set_xlabel('Emotion Classes')\n",
    "    ax1.set_ylabel('Number of Images')\n",
    "    ax1.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for i, v in enumerate(train_counts):\n",
    "        ax1.text(i, v + max(train_counts)*0.01, str(v), ha='center', va='bottom')\n",
    "    \n",
    "    # Validation distribution\n",
    "    ax2.bar(class_names, val_counts, color='lightcoral', alpha=0.8)\n",
    "    ax2.set_title('Validation Dataset Distribution', fontsize=14, fontweight='bold')\n",
    "    ax2.set_xlabel('Emotion Classes')\n",
    "    ax2.set_ylabel('Number of Images')\n",
    "    ax2.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for i, v in enumerate(val_counts):\n",
    "        ax2.text(i, v + max(val_counts)*0.01, str(v), ha='center', va='bottom')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../results/cnn_dataset_distribution.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Create visualizations directory\n",
    "os.makedirs(config.models_dir, exist_ok=True)
os.makedirs(config.results_dir, exist_ok=True)\n",
    "plot_dataset_distribution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define CNN Model\n",
    "class EmotionCNN(nn.Module):\n",
    "    def __init__(self, num_classes=7):\n",
    "        super(EmotionCNN, self).__init__()\n",
    "        \n",
    "        # Use ResNet18 as backbone\n",
    "        self.backbone = models.resnet18(pretrained=True)\n",
    "        \n",
    "        # Modify the final layer\n",
    "        self.backbone.fc = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(self.backbone.fc.in_features, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)\n",
    "\n",
    "# Initialize model\n",
    "model = EmotionCNN(num_classes=config.num_classes).to(config.device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=config.learning_rate, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=5, factor=0.5)\n",
    "\n",
    "print(f\"Model initialized with {sum(p.numel() for p in model.parameters())} parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function with comprehensive metrics\n",
    "def train_model():\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "    learning_rates = []\n",
    "    \n",
    "    best_val_acc = 0.0\n",
    "    patience_counter = 0\n",
    "    \n",
    "    for epoch in range(config.num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "        \n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.to(config.device), target.to(config.device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total_train += target.size(0)\n",
    "            correct_train += (predicted == target).sum().item()\n",
    "            \n",
    "            if batch_idx % 50 == 0:\n",
    "                print(f'Epoch {epoch+1}/{config.num_epochs}, Batch {batch_idx}/{len(train_loader)}, Loss: {loss.item():.4f}')\n",
    "        \n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_acc = 100. * correct_train / total_train\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct_val = 0\n",
    "        total_val = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for data, target in val_loader:\n",
    "                data, target = data.to(config.device), target.to(config.device)\n",
    "                output = model(data)\n",
    "                val_loss += criterion(output, target).item()\n",
    "                _, predicted = torch.max(output.data, 1)\n",
    "                total_val += target.size(0)\n",
    "                correct_val += (predicted == target).sum().item()\n",
    "        \n",
    "        val_loss /= len(val_loader)\n",
    "        val_acc = 100. * correct_val / total_val\n",
    "        \n",
    "        # Learning rate scheduling\n",
    "        scheduler.step(val_loss)\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        \n",
    "        # Store metrics\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        train_accuracies.append(train_acc)\n",
    "        val_accuracies.append(val_acc)\n",
    "        learning_rates.append(current_lr)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{config.num_epochs}:')\n",
    "        print(f'  Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%')\n",
    "        print(f'  Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n",
    "        print(f'  Learning Rate: {current_lr:.6f}')\n",
    "        print('-' * 50)\n",
    "        \n",
    "        # Early stopping and best model saving\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            patience_counter = 0\n",
    "            # Save best model\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'best_val_acc': best_val_acc,\n",
    "                'class_names': class_names\n",
    "            }, os.path.join(config.models_dir, config.model_name))\n",
    "            print(f'New best model saved with validation accuracy: {best_val_acc:.2f}%')\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            \n",
    "        if patience_counter >= config.patience:\n",
    "            print(f'Early stopping triggered after {epoch+1} epochs')\n",
    "            break\n",
    "    \n",
    "    return {\n",
    "        'train_losses': train_losses,\n",
    "        'val_losses': val_losses,\n",
    "        'train_accuracies': train_accuracies,\n",
    "        'val_accuracies': val_accuracies,\n",
    "        'learning_rates': learning_rates,\n",
    "        'best_val_acc': best_val_acc\n",
    "    }\n",
    "\n",
    "# Create checkpoint directory\n",
    "os.makedirs(config.checkpoint_dir, exist_ok=True)\n",
    "\n",
    "# Start training\n",
    "print(\"Starting training...\")\n",
    "training_history = train_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}  {

   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive visualization function\n",
    "def plot_training_results(history):\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    \n",
    "    # Loss curves\n",
    "    axes[0, 0].plot(history['train_losses'], label='Training Loss', color='blue', linewidth=2)\n",
    "    axes[0, 0].plot(history['val_losses'], label='Validation Loss', color='red', linewidth=2)\n",
    "    axes[0, 0].set_title('Training and Validation Loss', fontsize=14, fontweight='bold')\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].set_ylabel('Loss')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Accuracy curves\n",
    "    axes[0, 1].plot(history['train_accuracies'], label='Training Accuracy', color='blue', linewidth=2)\n",
    "    axes[0, 1].plot(history['val_accuracies'], label='Validation Accuracy', color='red', linewidth=2)\n",
    "    axes[0, 1].set_title('Training and Validation Accuracy', fontsize=14, fontweight='bold')\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('Accuracy (%)')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Learning rate\n",
    "    axes[0, 2].plot(history['learning_rates'], color='green', linewidth=2)\n",
    "    axes[0, 2].set_title('Learning Rate Schedule', fontsize=14, fontweight='bold')\n",
    "    axes[0, 2].set_xlabel('Epoch')\n",
    "    axes[0, 2].set_ylabel('Learning Rate')\n",
    "    axes[0, 2].set_yscale('log')\n",
    "    axes[0, 2].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Overfitting analysis\n",
    "    train_val_diff = np.array(history['train_accuracies']) - np.array(history['val_accuracies'])\n",
    "    axes[1, 0].plot(train_val_diff, color='purple', linewidth=2)\n",
    "    axes[1, 0].axhline(y=5, color='red', linestyle='--', alpha=0.7, label='Overfitting Threshold (5%)')\n",
    "    axes[1, 0].axhline(y=10, color='red', linestyle='-', alpha=0.7, label='Severe Overfitting (10%)')\n",
    "    axes[1, 0].set_title('Overfitting Analysis (Train - Val Accuracy)', fontsize=14, fontweight='bold')\n",
    "    axes[1, 0].set_xlabel('Epoch')\n",
    "    axes[1, 0].set_ylabel('Accuracy Difference (%)')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Loss difference analysis\n",
    "    loss_diff = np.array(history['val_losses']) - np.array(history['train_losses'])\n",
    "    axes[1, 1].plot(loss_diff, color='orange', linewidth=2)\n",
    "    axes[1, 1].axhline(y=0, color='black', linestyle='-', alpha=0.5)\n",
    "    axes[1, 1].set_title('Loss Difference Analysis (Val - Train)', fontsize=14, fontweight='bold')\n",
    "    axes[1, 1].set_xlabel('Epoch')\n",
    "    axes[1, 1].set_ylabel('Loss Difference')\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Performance summary\n",
    "    axes[1, 2].axis('off')\n",
    "    \n",
    "    # Analysis text\n",
    "    final_train_acc = history['train_accuracies'][-1]\n",
    "    final_val_acc = history['val_accuracies'][-1]\n",
    "    best_val_acc = max(history['val_accuracies'])\n",
    "    final_diff = final_train_acc - final_val_acc\n",
    "    \n",
    "    analysis_text = f\"\"\"PERFORMANCE ANALYSIS\n",
    "    \n",
    "Final Training Accuracy: {final_train_acc:.2f}%\n",
    "Final Validation Accuracy: {final_val_acc:.2f}%\n",
    "Best Validation Accuracy: {best_val_acc:.2f}%\n",
    "Accuracy Gap: {final_diff:.2f}%\n",
    "\n",
    "MODEL STATUS:\n",
    "\"\"\"\n",
    "    \n",
    "    if final_diff > 10:\n",
    "        status = \"âš ï¸ OVERFITTING DETECTED\\nâ€¢ Reduce model complexity\\nâ€¢ Add more regularization\\nâ€¢ Increase dropout\\nâ€¢ Get more data\"\n",
    "        color = 'red'\n",
    "    elif final_diff > 5:\n",
    "        status = \"âš¡ MILD OVERFITTING\\nâ€¢ Monitor closely\\nâ€¢ Consider early stopping\\nâ€¢ Tune regularization\"\n",
    "        color = 'orange'\n",
    "    elif final_val_acc < 60:\n",
    "        status = \"ðŸ“ˆ UNDERFITTING\\nâ€¢ Increase model complexity\\nâ€¢ Reduce regularization\\nâ€¢ Train longer\\nâ€¢ Check data quality\"\n",
    "        color = 'blue'\n",
    "    else:\n",
    "        status = \"âœ… GOOD PERFORMANCE\\nâ€¢ Model is well-balanced\\nâ€¢ Consider fine-tuning\\nâ€¢ Ready for deployment\"\n",
    "        color = 'green'\n",
    "    \n",
    "    axes[1, 2].text(0.1, 0.7, analysis_text, fontsize=12, fontweight='bold', \n",
    "                   verticalalignment='top', transform=axes[1, 2].transAxes)\n",
    "    axes[1, 2].text(0.1, 0.3, status, fontsize=11, color=color, fontweight='bold',\n",
    "                   verticalalignment='top', transform=axes[1, 2].transAxes)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../results/cnn_training_analysis.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Plot training results\n",
    "plot_training_results(training_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed evaluation on test set\n",
    "def evaluate_model():\n",
    "    # Load best model\n",
    "    checkpoint = torch.load(os.path.join(config.models_dir, config.model_name))\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.eval()\n",
    "    \n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in val_loader:\n",
    "            data, target = data.to(config.device), target.to(config.device)\n",
    "            output = model(data)\n",
    "            probs = torch.softmax(output, dim=1)\n",
    "            _, predicted = torch.max(output, 1)\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(target.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "    \n",
    "    return np.array(all_preds), np.array(all_labels), np.array(all_probs)\n",
    "\n",
    "# Get predictions\n",
    "predictions, true_labels, probabilities = evaluate_model()\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = (predictions == true_labels).mean() * 100\n",
    "f1 = f1_score(true_labels, predictions, average='weighted') * 100\n",
    "precision = precision_score(true_labels, predictions, average='weighted') * 100\n",
    "recall = recall_score(true_labels, predictions, average='weighted') * 100\n",
    "\n",
    "print(f\"\\nFinal Model Performance:\")\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "print(f\"F1-Score: {f1:.2f}%\")\n",
    "print(f\"Precision: {precision:.2f}%\")\n",
    "print(f\"Recall: {recall:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix and Classification Report\n",
    "def plot_evaluation_metrics(y_true, y_pred, y_probs, class_names):\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    sns.heatmap(cm_normalized, annot=True, fmt='.2f', cmap='Blues', \n",
    "                xticklabels=class_names, yticklabels=class_names, ax=axes[0, 0])\n",
    "    axes[0, 0].set_title('Normalized Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "    axes[0, 0].set_xlabel('Predicted Label')\n",
    "    axes[0, 0].set_ylabel('True Label')\n",
    "    \n",
    "    # Per-class accuracy\n",
    "    class_accuracies = cm.diagonal() / cm.sum(axis=1) * 100\n",
    "    bars = axes[0, 1].bar(class_names, class_accuracies, color='skyblue', alpha=0.8)\n",
    "    axes[0, 1].set_title('Per-Class Accuracy', fontsize=14, fontweight='bold')\n",
    "    axes[0, 1].set_xlabel('Emotion Classes')\n",
    "    axes[0, 1].set_ylabel('Accuracy (%)')\n",
    "    axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar, acc in zip(bars, class_accuracies):\n",
    "        axes[0, 1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1, \n",
    "                       f'{acc:.1f}%', ha='center', va='bottom')\n",
    "    \n",
    "    # ROC Curves (One-vs-Rest)\n",
    "    from sklearn.preprocessing import label_binarize\n",
    "    y_true_bin = label_binarize(y_true, classes=range(len(class_names)))\n",
    "    \n",
    "    colors = plt.cm.Set1(np.linspace(0, 1, len(class_names)))\n",
    "    for i, (class_name, color) in enumerate(zip(class_names, colors)):\n",
    "        fpr, tpr, _ = roc_curve(y_true_bin[:, i], y_probs[:, i])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        axes[1, 0].plot(fpr, tpr, color=color, linewidth=2,\n",
    "                       label=f'{class_name} (AUC = {roc_auc:.2f})')\n",
    "    \n",
    "    axes[1, 0].plot([0, 1], [0, 1], 'k--', linewidth=1)\n",
    "    axes[1, 0].set_xlim([0.0, 1.0])\n",
    "    axes[1, 0].set_ylim([0.0, 1.05])\n",
    "    axes[1, 0].set_xlabel('False Positive Rate')\n",
    "    axes[1, 0].set_ylabel('True Positive Rate')\n",
    "    axes[1, 0].set_title('ROC Curves (One-vs-Rest)', fontsize=14, fontweight='bold')\n",
    "    axes[1, 0].legend(loc=\"lower right\", fontsize=8)\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Classification Report as text\n",
    "    axes[1, 1].axis('off')\n",
    "    report = classification_report(y_true, y_pred, target_names=class_names, digits=3)\n",
    "    axes[1, 1].text(0.1, 0.9, 'Classification Report:\\n\\n' + report, \n",
    "                   fontsize=10, fontfamily='monospace',\n",
    "                   verticalalignment='top', transform=axes[1, 1].transAxes)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../results/cnn_evaluation_metrics.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Plot evaluation metrics\n",
    "plot_evaluation_metrics(true_labels, predictions, probabilities, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save training metrics and model info\n",
    "metrics_data = {\n",
    "    'model_type': 'CNN',\n",
    "    'model_name': config.model_name,\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'training_history': training_history,\n",
    "    'final_metrics': {\n",
    "        'accuracy': float(accuracy),\n",
    "        'f1_score': float(f1),\n",
    "        'precision': float(precision),\n",
    "        'recall': float(recall)\n",
    "    },\n",
    "    'config': {\n",
    "        'batch_size': config.batch_size,\n",
    "        'learning_rate': config.learning_rate,\n",
    "        'num_epochs': config.num_epochs,\n",
    "        'img_size': config.img_size,\n",
    "        'num_classes': config.num_classes\n",
    "    },\n",
    "    'class_names': class_names\n",
    "}\n",
    "\n",
    "# Save metrics\n",
    "with open(os.path.join(config.results_dir, 'cnn_metrics.json'), 'w') as f:\n",
    "    json.dump(metrics_data, f, indent=2)\n",
    "\n",
    "print(\"\\nâœ… Training completed successfully!\")\n",
    "print(f\"ðŸ“ Model saved as: {config.model_name}\")\n",
    "print(f\"ðŸ“Š Metrics saved as: cnn_metrics.json\")\n",
    "print(f\"ðŸ“ˆ Visualizations saved in: ../results/\")\n",
    "print(f\"ðŸŽ¯ Best validation accuracy: {training_history['best_val_acc']:.2f}%\")"
   ]
  }
 ]
}